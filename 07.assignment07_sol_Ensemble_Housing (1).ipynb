{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23789d8-b957-4de1-9469-c40c55bd96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import VotingRegressor, BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14bd7c12-3cde-4051-adfe-9786ac5ec13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\") \n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\" \n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\") \n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "def split_train_test(X, y, test_ratio = 0.2):\n",
    "\n",
    "    #---stratified sampling\n",
    "    X_columns = X.columns\n",
    "    y_columns = y.columns\n",
    "    data = pd.concat([X,y], axis = 1)\n",
    "        \n",
    "    df_income_cat = data.copy()\n",
    "    df_income_cat[\"income_cat\"] = pd.cut(df_income_cat[\"median_income\"],\n",
    "                                       bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                                       labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "    dftrain_strat, dftest_strat = train_test_split(\n",
    "        df_income_cat, test_size=test_ratio, stratify=df_income_cat[\"income_cat\"], random_state=42)\n",
    "\n",
    "    dftrain_strat = dftrain_strat.drop(['income_cat'], axis = 1)\n",
    "    dftest_strat = dftest_strat.drop(['income_cat'], axis = 1)\n",
    "\n",
    "    X_train = dftrain_strat[X_columns]\n",
    "    y_train = dftrain_strat[y_columns]\n",
    "    \n",
    "    X_test = dftest_strat[X_columns]\n",
    "    y_test = dftest_strat[y_columns]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "Xtrain_prepared_col_names = []\n",
    "\n",
    "def column_ratio(X):\n",
    "    return X[:, [0]] / X[:, [1]]\n",
    "\n",
    "def ratio_name(function_transformer, feature_names_in):\n",
    "    return [\"ratio\"]  # feature names out\n",
    "\n",
    "def fill_na(X, strategy = 'median'):\n",
    "    #X: ndarray array of shape (n_samples, n_features)\n",
    "    #return ndarray of shape (n_samples, n_features) with missing values filled by the strategy\n",
    "\n",
    "    imputer = SimpleImputer(strategy = strategy)\n",
    "    imputer.fit(X)\n",
    "\n",
    "    return imputer.transform(X)\n",
    "\n",
    "def get_outlier_indices(X):\n",
    "    #X: ndarray of shape (n_samples, n_features)\n",
    "    #y: label of shape (n_samples, k = 1)\n",
    "    #return the indices of outliers in X\n",
    "    \n",
    "    isolation_forest = IsolationForest(random_state = 42)\n",
    "    outlier_pred = isolation_forest.fit_predict(X)\n",
    "\n",
    "    return outlier_pred\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        FunctionTransformer(column_ratio, feature_names_out=ratio_name))\n",
    "\n",
    "def prepare_for_train(Xtrain, Xtest, ytrain, ytest):\n",
    "    \n",
    "    #prepare data for training\n",
    "    #---create 2 pipelines for nummerical columns and catergorical columns\n",
    "    #---then merge them into one\n",
    "    \n",
    "    #Note DecisionTree can work with missing values and different scale but RandomForest cannot\n",
    "\n",
    "    num_pipeline = make_pipeline(SimpleImputer(strategy = 'median'),\n",
    "                                 StandardScaler())\n",
    "\n",
    "    #num_pipeline = make_pipeline('passthrough')\n",
    "\n",
    "    cat_pipeline = make_pipeline(SimpleImputer(strategy = \"most_frequent\"),\\\n",
    "                                 OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "\n",
    "    preprocessing = ColumnTransformer([(\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),\\\n",
    "                                       (\"cat\", cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "                                       (\"bedrooms\", ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n",
    "                                       (\"rooms_per_house\", ratio_pipeline(), [\"total_rooms\", \"households\"]),\n",
    "                                       (\"people_per_house\", ratio_pipeline(), [\"population\", \"households\"])]\n",
    "                                     )\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    #---drop outliers in the training set outside the pipeline, do not drop outliers in the test\n",
    "    \"\"\"\n",
    "    DecisionTree can work with outliers, so we do not need this code\n",
    "    I mostly use DecisionTree throughout this assignment, so I chose again to not drop outliers\n",
    "    \n",
    "    \n",
    "    Xtrain_num = Xtrain.select_dtypes(include=[np.number])\n",
    "    Xtrain_num = fill_na(Xtrain_num)\n",
    "    outlier_indices = get_outlier_indices(Xtrain_num)\n",
    "\n",
    "    Xtrain = Xtrain.iloc[outlier_indices == 1]\n",
    "    ytrain = ytrain.iloc[outlier_indices == 1]\n",
    "    \"\"\"\n",
    "\n",
    "    #---pass Xtrain, Xtest thru the pipeline to get the prepared versions \n",
    "    \n",
    "    Xtrain_prepared = preprocessing.fit_transform(Xtrain, ytrain)\n",
    "\n",
    "    Xtest_prepared = preprocessing.fit_transform(Xtest, ytest)\n",
    "\n",
    "    ytrain_prepared, ytest_prepared = ytrain, ytest\n",
    "    \n",
    "    ytrain_prepared, ytest_prepared = np.ravel(ytrain_prepared, ), np.ravel(ytest_prepared, )\n",
    "\n",
    "    global Xtrain_prepared_col_names \n",
    "    Xtrain_prepared_col_names = preprocessing.get_feature_names_out()\n",
    "\n",
    "    return Xtrain_prepared, Xtest_prepared, ytrain_prepared, ytest_prepared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4ee868-640a-4031-a3af-66b2e0bbca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 load data\n",
    "\n",
    "housing = load_housing_data() # housing is a dataframe\n",
    "\n",
    "housing_X = housing.drop(\"median_house_value\", axis=1)\n",
    "housing_y = housing[[\"median_house_value\"]].copy()    \n",
    "\n",
    "#2 split train, test sets\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = split_train_test(housing_X, housing_y, test_ratio = 0.25)\n",
    "\n",
    "#3 prepare data for training\n",
    "\n",
    "Xtrain_prepared, Xtest_prepared, ytrain_prepared, ytest_prepared = prepare_for_train(Xtrain, Xtest, ytrain, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63df674-7f7c-4fc1-9457-081a694340a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;dt&#x27;,\n",
       "                             DecisionTreeRegressor(max_depth=5,\n",
       "                                                   min_samples_leaf=20,\n",
       "                                                   random_state=42)),\n",
       "                            (&#x27;svr&#x27;, SVR()),\n",
       "                            (&#x27;sgd&#x27;,\n",
       "                             SGDRegressor(max_iter=5000, n_iter_no_change=500,\n",
       "                                          random_state=42,\n",
       "                                          validation_fraction=0.2)),\n",
       "                            (&#x27;lr&#x27;, LinearRegression())],\n",
       "                n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;dt&#x27;,\n",
       "                             DecisionTreeRegressor(max_depth=5,\n",
       "                                                   min_samples_leaf=20,\n",
       "                                                   random_state=42)),\n",
       "                            (&#x27;svr&#x27;, SVR()),\n",
       "                            (&#x27;sgd&#x27;,\n",
       "                             SGDRegressor(max_iter=5000, n_iter_no_change=500,\n",
       "                                          random_state=42,\n",
       "                                          validation_fraction=0.2)),\n",
       "                            (&#x27;lr&#x27;, LinearRegression())],\n",
       "                n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=5, min_samples_leaf=20, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sgd</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(max_iter=5000, n_iter_no_change=500, random_state=42,\n",
       "             validation_fraction=0.2)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('dt',\n",
       "                             DecisionTreeRegressor(max_depth=5,\n",
       "                                                   min_samples_leaf=20,\n",
       "                                                   random_state=42)),\n",
       "                            ('svr', SVR()),\n",
       "                            ('sgd',\n",
       "                             SGDRegressor(max_iter=5000, n_iter_no_change=500,\n",
       "                                          random_state=42,\n",
       "                                          validation_fraction=0.2)),\n",
       "                            ('lr', LinearRegression())],\n",
       "                n_jobs=-1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with VotingRegressor\n",
    "\n",
    "voting_reg = VotingRegressor(n_jobs = -1, estimators=\n",
    "            [('dt', DecisionTreeRegressor(random_state=42, max_depth = 5, min_samples_leaf=20)),\n",
    "            ('svr', SVR()),\n",
    "            ('sgd', SGDRegressor(max_iter = 5000,\n",
    "                                n_iter_no_change = 500, \n",
    "                                validation_fraction = 0.2,\n",
    "                                random_state=42)),\n",
    "            ('lr', LinearRegression())] )\n",
    "voting_reg.fit(Xtrain_prepared, ytrain_prepared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04dbf505-bc0a-42f9-bea0-0b6d3fd5c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 73709.64158487524\n",
      "error rates: 0.3542513385807372\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_reg.predict(Xtest_prepared)\n",
    "\n",
    "rmse = mean_squared_error(ytest_prepared, y_pred, squared=False)\n",
    "voting_scores = {\"RMSE\": rmse, \"Error Rate\": rmse / np.mean(ytest_prepared)}\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(\"error rates:\", rmse / np.mean(ytest_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b66942d-4d56-4243-a712-99ecec92385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 73709.64158487524, 'Error Rate': 0.3542513385807372}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb437f1b-d215-495a-a4e5-5578c7828cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc of each classifier:\n",
      "Root Mean Squared Error for dt: 66770.75541526881\n",
      "error rates: 0.3209027879571126\n",
      "Root Mean Squared Error for svr: 118511.70835576176\n",
      "error rates: 0.569571774055854\n",
      "Root Mean Squared Error for sgd: 104991.9001899807\n",
      "error rates: 0.5045950622295212\n",
      "Root Mean Squared Error for lr: 69137.61127430637\n",
      "error rates: 0.3322779871612254\n"
     ]
    }
   ],
   "source": [
    "#the ensemble performs slightly better than all 3 regressors\n",
    "print(\"Test acc of each classifier:\")\n",
    "#individual_regressors = voting_reg.named_estimators_.items()\n",
    "# for name, reg in voting_reg.named_estimators_.items():\n",
    "#     print(name, \"=\", mean_squared_error(reg.predict(Xtest_prepared, ytest_prepared))\n",
    "for name, regressor in voting_reg.named_estimators_.items():\n",
    "    ypred_individual = regressor.predict(Xtest_prepared)\n",
    "    rmse_individual = mean_squared_error(ytest_prepared, ypred_individual, squared=False)\n",
    "    print(f'Root Mean Squared Error for {name}: {rmse_individual}')\n",
    "    print(\"error rates:\", rmse_individual / np.mean(ytest_prepared))\n",
    "\n",
    "#DecisionTree was the best of the algorithms in VotingRegressor,\n",
    "#I will be mainly using DecisionTree as the base regressor for following ensemble algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d269dce-743f-49be-9b07-a08789baace8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingRegressor(estimator=DecisionTreeRegressor(max_depth=5,\n",
       "                                                 min_samples_leaf=20,\n",
       "                                                 random_state=42),\n",
       "                 max_samples=500, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                 random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(estimator=DecisionTreeRegressor(max_depth=5,\n",
       "                                                 min_samples_leaf=20,\n",
       "                                                 random_state=42),\n",
       "                 max_samples=500, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                 random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=5, min_samples_leaf=20, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=5, min_samples_leaf=20, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingRegressor(estimator=DecisionTreeRegressor(max_depth=5,\n",
       "                                                 min_samples_leaf=20,\n",
       "                                                 random_state=42),\n",
       "                 max_samples=500, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                 random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging Regressor\n",
    "\n",
    "bagging_reg = BaggingRegressor(DecisionTreeRegressor(max_depth = 5, \n",
    "                                                       min_samples_leaf=20,\n",
    "                                                       random_state=42),\n",
    "                                n_estimators = 500, max_samples = 500,  oob_score = True,\n",
    "                                n_jobs=-1, bootstrap = True, random_state=42)\n",
    "bagging_reg.fit(Xtrain_prepared, ytrain_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692f21fc-d2c5-4fc7-855c-7521c6628310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 65270.91885579137\n",
      "error rates: 0.313694516455271\n"
     ]
    }
   ],
   "source": [
    "ypred = bagging_reg.predict(Xtest_prepared)\n",
    "\n",
    "rmse = mean_squared_error(ytest_prepared, ypred, squared=False)\n",
    "bagging_scores = {\"RMSE\": rmse, \"Error Rate\": rmse / np.mean(ytest_prepared)}\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(\"error rates:\", rmse / np.mean(ytest_prepared))\n",
    "\n",
    "#Better than Voting, but still not that impressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0d0a8d-433b-4590-97d9-6288d421957c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Xtest_prepared[:50, 0], ytest_prepared[:50], label='Actual Values')\n",
    "plt.scatter(Xtest_prepared[:50, 0], ypred[:50], label='Predicted Values', marker='^')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# little visualization of a small subset of the predicted versus actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f6d2a27-7a36-4cf9-b023-6686485ace94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "RandomForestRegressor: \n",
      "train, test RMSEs:  48017.802043270574 53426.6889157852\n",
      "train, test error rates: 0.23258741817613288 0.2567706972575639\n"
     ]
    }
   ],
   "source": [
    "# Train with RandomForest\n",
    "\n",
    "\n",
    "RFRegressor = RandomForestRegressor(max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8,\n",
    "                                    n_estimators = 500, max_samples = 0.5,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "RFRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "\n",
    "test_predictions = RFRegressor.predict(Xtest_prepared)\n",
    "train_predictions = RFRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "test_rmse = mean_squared_error(ytest_prepared, test_predictions, squared=False)\n",
    "train_rmse = mean_squared_error(ytrain_prepared, train_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"RandomForestRegressor: \")\n",
    "print(\"train, test RMSEs: \", train_rmse, test_rmse) # prints\n",
    "print(\"train, test error rates:\", train_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 test_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "#here RF gives us better error rate (about 26%), compared with other methods including \n",
    "#LR, SGDRegressor, SVR, DecisionTree (about 32-56%)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80226310-992c-4586-a429-fc49b4f134c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-61955.187 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-61217.121 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-61093.975 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-63509.916 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-65170.667 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-61696.310 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-61302.727 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-61179.562 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-63449.823 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-65235.263 total time=   1.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-61697.424 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-61306.646 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-61186.794 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-63381.648 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-65219.528 total time=   2.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-61955.187 total time=   0.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-61217.121 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-61093.975 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-63509.916 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-65170.667 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-61696.310 total time=   1.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-61302.727 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-61179.562 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-63449.823 total time=   1.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-65235.263 total time=   1.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-61697.424 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-61306.646 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-61186.794 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-63381.648 total time=   2.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-65219.528 total time=   2.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-61951.198 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-61276.492 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-61100.753 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-63511.147 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-65149.889 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-61695.749 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-61312.516 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-61187.240 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-63453.197 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-65234.709 total time=   1.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-61703.673 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-61313.999 total time=   2.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-61186.640 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-63382.299 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-65217.327 total time=   2.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-61902.585 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-61347.973 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-61144.318 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-63484.376 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-65203.710 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-61719.418 total time=   1.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-61398.347 total time=   1.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-61192.449 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-63439.871 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-65269.259 total time=   1.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-61737.765 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-61377.490 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-61169.998 total time=   2.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-63388.381 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-65257.028 total time=   2.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-61902.585 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-61347.973 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-61144.318 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-63484.376 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-65203.710 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-61719.418 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-61398.347 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-61192.449 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-63439.871 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-65269.259 total time=   1.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-61737.765 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-61377.490 total time=   2.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-61169.998 total time=   2.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-63388.381 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-65257.028 total time=   2.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-61902.585 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-61347.973 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-61144.318 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-63484.376 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-65203.710 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-61719.418 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-61398.347 total time=   2.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-61192.449 total time=   1.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-63439.871 total time=   1.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-65269.259 total time=   1.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-61737.765 total time=   2.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-61377.490 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-61169.998 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-63388.381 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-65257.028 total time=   2.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-61910.702 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-61347.347 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-61160.780 total time=   0.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-63535.141 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-65255.988 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-61764.282 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-61411.404 total time=   1.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-61243.706 total time=   1.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-63498.264 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-65288.569 total time=   1.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-61794.904 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-61396.348 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-61227.413 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-63429.197 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-65277.800 total time=   2.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-61910.702 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-61347.347 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-61160.780 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-63535.141 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-65255.988 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-61764.282 total time=   1.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-61411.404 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-61243.706 total time=   1.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-63498.264 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-65288.569 total time=   1.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-61794.904 total time=   2.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-61396.348 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-61227.413 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-63429.197 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-65277.800 total time=   2.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-61910.702 total time=   0.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-61347.347 total time=   0.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-61160.780 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-63535.141 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-65255.988 total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-61764.282 total time=   1.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-61411.404 total time=   1.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-61243.706 total time=   1.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-63498.264 total time=   1.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-65288.569 total time=   1.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-61794.904 total time=   2.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-61396.348 total time=   2.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-61227.413 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-63429.197 total time=   2.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-65277.800 total time=   2.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-51938.266 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-52988.255 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-51700.333 total time=   0.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-53815.662 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-54985.544 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-51552.415 total time=   1.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-52747.791 total time=   1.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-51604.528 total time=   1.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-53634.685 total time=   2.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-54865.151 total time=   2.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-51533.779 total time=   4.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-52668.674 total time=   4.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-51604.787 total time=   4.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-53586.984 total time=   4.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-54884.588 total time=   4.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-51938.266 total time=   0.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-52988.255 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-51700.333 total time=   0.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-53815.662 total time=   0.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-54985.544 total time=   0.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-51552.415 total time=   2.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-52747.791 total time=   1.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-51604.528 total time=   1.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-53634.685 total time=   1.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-54865.151 total time=   1.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-51533.779 total time=   3.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-52668.674 total time=   3.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-51604.787 total time=   3.6s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-53586.984 total time=   3.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-54884.588 total time=   3.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-52035.564 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-53019.872 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-51700.053 total time=   0.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-53955.975 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-54951.436 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-51708.840 total time=   1.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-52814.789 total time=   1.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-51589.745 total time=   1.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-53717.951 total time=   1.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-54831.646 total time=   1.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-51692.975 total time=   3.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-52716.591 total time=   3.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-51623.025 total time=   3.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-53626.398 total time=   3.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-54862.548 total time=   3.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-52681.248 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-53529.996 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-52573.994 total time=   0.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-54584.597 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-55573.616 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-52393.347 total time=   1.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-53354.557 total time=   1.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-52449.581 total time=   1.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-54323.648 total time=   1.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-55462.595 total time=   1.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-52349.039 total time=   3.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-53274.477 total time=   3.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-52427.575 total time=   3.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-54304.549 total time=   3.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-55467.550 total time=   3.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-52681.248 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-53529.996 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-52573.994 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-54584.597 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-55573.616 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-52393.347 total time=   1.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-53354.557 total time=   1.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-52449.581 total time=   1.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-54323.648 total time=   1.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-55462.595 total time=   1.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-52349.039 total time=   3.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-53274.477 total time=   3.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-52427.575 total time=   3.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-54304.549 total time=   3.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-55467.550 total time=   3.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-52681.248 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-53529.996 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-52573.994 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-54584.597 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-55573.616 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-52393.347 total time=   1.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-53354.557 total time=   1.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-52449.581 total time=   1.6s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-54323.648 total time=   1.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-55462.595 total time=   1.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-52349.039 total time=   3.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-53274.477 total time=   3.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-52427.575 total time=   3.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-54304.549 total time=   3.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-55467.550 total time=   3.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-53293.452 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-54176.970 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-53407.917 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-55267.798 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-56424.170 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-53024.917 total time=   1.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-54100.627 total time=   1.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-53358.369 total time=   1.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-55166.068 total time=   1.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-56316.676 total time=   1.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-53002.889 total time=   3.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-53975.903 total time=   2.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-53260.963 total time=   2.9s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-55125.367 total time=   3.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-56276.838 total time=   2.9s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-53293.452 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-54176.970 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-53407.917 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-55267.798 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-56424.170 total time=   0.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-53024.917 total time=   1.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-54100.627 total time=   1.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-53358.369 total time=   1.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-55166.068 total time=   1.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-56316.676 total time=   1.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-53002.889 total time=   2.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-53975.903 total time=   3.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-53260.963 total time=   3.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-55125.367 total time=   2.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-56276.838 total time=   3.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-53293.452 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-54176.970 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-53407.917 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-55267.798 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-56424.170 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-53024.917 total time=   1.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-54100.627 total time=   1.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-53358.369 total time=   1.6s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-55166.068 total time=   1.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-56316.676 total time=   1.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-53002.889 total time=   2.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-53975.903 total time=   2.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-53260.963 total time=   2.9s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-55125.367 total time=   2.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-56276.838 total time=   3.0s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-50069.810 total time=   0.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-51165.829 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-50271.719 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-52012.266 total time=   0.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=-53146.276 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-49906.964 total time=   1.8s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-51060.710 total time=   1.8s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-49966.925 total time=   1.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-51871.637 total time=   1.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=-52961.127 total time=   1.8s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-49886.368 total time=   3.8s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-50995.271 total time=   3.7s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-49956.892 total time=   3.7s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-51802.910 total time=   3.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=-52948.345 total time=   3.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-50069.810 total time=   0.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-51165.829 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-50271.719 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-52012.266 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=-53146.276 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-49906.964 total time=   1.9s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-51060.710 total time=   1.8s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-49966.925 total time=   1.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-51871.637 total time=   1.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=-52961.127 total time=   1.8s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-49886.368 total time=   3.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-50995.271 total time=   3.7s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-49956.892 total time=   3.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-51802.910 total time=   3.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=1000;, score=-52948.345 total time=   3.8s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-50388.456 total time=   0.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-51454.840 total time=   0.5s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-50066.591 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-52068.674 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=-53225.270 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-50005.349 total time=   1.8s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-51304.437 total time=   1.8s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-49917.019 total time=   1.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-51926.911 total time=   1.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=-53131.253 total time=   1.9s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-50040.121 total time=   3.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-51205.363 total time=   3.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-49946.890 total time=   3.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-51821.737 total time=   3.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=-53122.573 total time=   3.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-51932.584 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-52596.935 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-51909.977 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-53781.436 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=100;, score=-54724.051 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-51534.930 total time=   1.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-52624.714 total time=   1.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-51652.948 total time=   1.7s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-53441.415 total time=   1.7s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=500;, score=-54572.340 total time=   1.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-51523.418 total time=   3.2s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-52491.149 total time=   3.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-51623.003 total time=   3.3s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-53365.084 total time=   3.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=2, n_estimators=1000;, score=-54557.352 total time=   3.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-51932.584 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-52596.935 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-51909.977 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-53781.436 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=100;, score=-54724.051 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-51534.930 total time=   1.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-52624.714 total time=   1.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-51652.948 total time=   1.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-53441.415 total time=   1.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=500;, score=-54572.340 total time=   1.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-51523.418 total time=   3.3s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-52491.149 total time=   3.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-51623.003 total time=   3.2s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-53365.084 total time=   3.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=5, n_estimators=1000;, score=-54557.352 total time=   3.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-51932.584 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-52596.935 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-51909.977 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-53781.436 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=100;, score=-54724.051 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-51534.930 total time=   1.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-52624.714 total time=   1.7s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-51652.948 total time=   1.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-53441.415 total time=   1.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=500;, score=-54572.340 total time=   1.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-51523.418 total time=   3.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-52491.149 total time=   3.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-51623.003 total time=   3.2s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-53365.084 total time=   3.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=10, min_samples_split=10, n_estimators=1000;, score=-54557.352 total time=   3.3s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-52790.352 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-53610.000 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-52833.161 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-54744.135 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=-55954.789 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-52477.960 total time=   1.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-53553.791 total time=   1.5s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-52734.692 total time=   1.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-54573.388 total time=   1.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=500;, score=-55815.812 total time=   1.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-52459.971 total time=   3.0s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-53432.083 total time=   3.1s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-52720.869 total time=   3.2s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-54520.683 total time=   3.0s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=2, n_estimators=1000;, score=-55754.076 total time=   3.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-52790.352 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-53610.000 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-52833.161 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-54744.135 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=-55954.789 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-52477.960 total time=   1.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-53553.791 total time=   1.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-52734.692 total time=   1.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-54573.388 total time=   1.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=500;, score=-55815.812 total time=   1.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-52459.971 total time=   3.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-53432.083 total time=   3.1s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-52720.869 total time=   3.0s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-54520.683 total time=   3.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=5, n_estimators=1000;, score=-55754.076 total time=   3.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-52790.352 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-53610.000 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-52833.161 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-54744.135 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=-55954.789 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-52477.960 total time=   1.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-53553.791 total time=   1.5s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-52734.692 total time=   1.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-54573.388 total time=   1.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=500;, score=-55815.812 total time=   1.7s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-52459.971 total time=   3.0s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-53432.083 total time=   3.0s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-52720.869 total time=   3.0s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-54520.683 total time=   3.0s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=15, min_samples_split=10, n_estimators=1000;, score=-55754.076 total time=   3.2s\n",
      "(15480, 16)\n",
      "RandomForestRegressor: \n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "train, test RMSEs:  38524.129043660614 50645.08405471659\n",
      "train, test error rates: 0.18660220440066816 0.24340219858834186\n"
     ]
    }
   ],
   "source": [
    "# Hypertune RandomForest\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [4, 10, 15]\n",
    "}\n",
    "\n",
    "# Create a RandomForestRegressor\n",
    "RFRegressor = RandomForestRegressor(min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8,\n",
    "                                    max_samples = 0.5,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=RFRegressor, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=5, verbose=3)\n",
    "grid_search.fit(Xtrain_prepared, ytrain_prepared)\n",
    "\n",
    "# Retrieve the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the testing data\n",
    "test_predictions = best_model.predict(Xtest_prepared)\n",
    "train_predictions = best_model.predict(Xtrain_prepared)\n",
    "\n",
    "# Evaluate the performance\n",
    "test_rmse = mean_squared_error(ytest_prepared, test_predictions, squared=False)\n",
    "train_rmse = mean_squared_error(ytrain_prepared, train_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"RandomForestRegressor: \")\n",
    "print(best_params)\n",
    "print(\"train, test RMSEs: \", train_rmse, test_rmse) # prints\n",
    "print(\"train, test error rates:\", train_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 test_rmse / np.mean(ytest_prepared))#.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f3fab7-500b-4e4e-b590-1fdac73753e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af6be92-fe49-45d1-8095-566cd5236933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "RandomForestRegressor: \n",
      "train, test RMSEs:  38524.129043660614 50645.08405471659\n",
      "train, test error rates: 0.18660220440066816 0.24340219858834186\n"
     ]
    }
   ],
   "source": [
    "# Train final with RandomForest\n",
    "\n",
    "\n",
    "RFRegressor = RandomForestRegressor(max_depth = 20, \n",
    "                                    min_samples_leaf=4, min_samples_split=2,\n",
    "                                    random_state=42, max_features = 0.8,\n",
    "                                    n_estimators = 1000, max_samples = 0.5,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "RFRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "\n",
    "test_predictions = RFRegressor.predict(Xtest_prepared)\n",
    "train_predictions = RFRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "test_rmse = mean_squared_error(ytest_prepared, test_predictions, squared=False)\n",
    "train_rmse = mean_squared_error(ytrain_prepared, train_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"RandomForestRegressor: \")\n",
    "print(\"train, test RMSEs: \", train_rmse, test_rmse) # prints\n",
    "print(\"train, test error rates:\", train_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 test_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "\n",
    "forest_scores = {\"RMSE\": test_rmse, \"Error Rate\": test_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "#hypertuning improvies error rate by 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3296e319-1d20-4e25-a66f-e114b133f69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "AdaBoostRegressor: \n",
      "train, test RMSEs:  40064.947707959436 51432.61306114301\n",
      "train, test error rates: 0.19406558297605392 0.24718709292101168\n"
     ]
    }
   ],
   "source": [
    "# Train with AdaBoostRegressor\n",
    "\n",
    "\n",
    "\n",
    "adaRegressor = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8), \n",
    "                                 n_estimators = 500, learning_rate = 0.01)\n",
    "\n",
    "\n",
    "adaRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "\n",
    "adatest_predictions = adaRegressor.predict(Xtest_prepared)\n",
    "adatrain_predictions = adaRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "adatest_rmse = mean_squared_error(ytest_prepared, adatest_predictions, squared=False)\n",
    "adatrain_rmse = mean_squared_error(ytrain_prepared, adatrain_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"AdaBoostRegressor: \")\n",
    "print(\"train, test RMSEs: \", adatrain_rmse, adatest_rmse) # prints\n",
    "print(\"train, test error rates:\", adatrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 adatest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "ada_scores = {\"RMSE\": adatest_rmse, \"Error Rate\": adatest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "# Error Rate is 0.24718709, slightly worse than Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4394882-5bd9-4dd7-978b-be0795e328ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV 1/3] END learning_rate=0.01, loss=linear, n_estimators=100;, score=-52895.925 total time=   8.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=linear, n_estimators=100;, score=-52439.002 total time=   8.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=linear, n_estimators=100;, score=-54330.795 total time=   8.6s\n",
      "[CV 1/3] END learning_rate=0.01, loss=linear, n_estimators=200;, score=-52172.004 total time=  17.1s\n",
      "[CV 2/3] END learning_rate=0.01, loss=linear, n_estimators=200;, score=-52478.985 total time=  17.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=linear, n_estimators=200;, score=-54533.752 total time=  17.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=linear, n_estimators=500;, score=-51588.915 total time=  41.9s\n",
      "[CV 2/3] END learning_rate=0.01, loss=linear, n_estimators=500;, score=-51872.396 total time=  42.0s\n",
      "[CV 3/3] END learning_rate=0.01, loss=linear, n_estimators=500;, score=-53799.196 total time=  41.8s\n",
      "[CV 1/3] END learning_rate=0.01, loss=square, n_estimators=100;, score=-52725.449 total time=   8.7s\n",
      "[CV 2/3] END learning_rate=0.01, loss=square, n_estimators=100;, score=-52766.184 total time=   8.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=square, n_estimators=100;, score=-54870.786 total time=   8.5s\n",
      "[CV 1/3] END learning_rate=0.01, loss=square, n_estimators=200;, score=-52361.031 total time=  17.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=square, n_estimators=200;, score=-52576.237 total time=  17.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=square, n_estimators=200;, score=-54562.433 total time=  17.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=square, n_estimators=500;, score=-51562.646 total time=  42.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=square, n_estimators=500;, score=-52081.197 total time=  42.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=square, n_estimators=500;, score=-53945.253 total time=  42.0s\n",
      "[CV 1/3] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=-52802.048 total time=   8.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=-52553.046 total time=   8.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=-54362.634 total time=   8.5s\n",
      "[CV 1/3] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=-52246.459 total time=  17.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=-52467.072 total time=  17.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=-54383.112 total time=  17.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=-51681.421 total time=  42.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=-51845.995 total time=  42.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=exponential, n_estimators=500;, score=-53918.634 total time=  42.1s\n",
      "[CV 1/3] END learning_rate=0.1, loss=linear, n_estimators=100;, score=-51013.044 total time=   7.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=linear, n_estimators=100;, score=-51777.541 total time=   7.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=linear, n_estimators=100;, score=-53512.171 total time=   7.9s\n",
      "[CV 1/3] END learning_rate=0.1, loss=linear, n_estimators=200;, score=-50794.382 total time=  14.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=linear, n_estimators=200;, score=-51483.805 total time=  14.4s\n",
      "[CV 3/3] END learning_rate=0.1, loss=linear, n_estimators=200;, score=-52935.584 total time=  14.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=linear, n_estimators=500;, score=-51099.262 total time=  31.7s\n",
      "[CV 2/3] END learning_rate=0.1, loss=linear, n_estimators=500;, score=-51595.202 total time=  31.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=linear, n_estimators=500;, score=-52596.997 total time=  31.6s\n",
      "[CV 1/3] END learning_rate=0.1, loss=square, n_estimators=100;, score=-51076.537 total time=   8.0s\n",
      "[CV 2/3] END learning_rate=0.1, loss=square, n_estimators=100;, score=-51992.579 total time=   7.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=square, n_estimators=100;, score=-53541.893 total time=   8.0s\n",
      "[CV 1/3] END learning_rate=0.1, loss=square, n_estimators=200;, score=-50718.312 total time=  14.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=square, n_estimators=200;, score=-51530.886 total time=  14.2s\n",
      "[CV 3/3] END learning_rate=0.1, loss=square, n_estimators=200;, score=-52936.651 total time=  14.5s\n",
      "[CV 1/3] END learning_rate=0.1, loss=square, n_estimators=500;, score=-50398.622 total time=  31.2s\n",
      "[CV 2/3] END learning_rate=0.1, loss=square, n_estimators=500;, score=-51561.588 total time=  29.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=square, n_estimators=500;, score=-52304.877 total time=  30.6s\n",
      "[CV 1/3] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=-51262.283 total time=   8.1s\n",
      "[CV 2/3] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=-51833.609 total time=   8.0s\n",
      "[CV 3/3] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=-53298.122 total time=   8.0s\n",
      "[CV 1/3] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=-50717.263 total time=  14.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=-51321.273 total time=  14.7s\n",
      "[CV 3/3] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=-53137.053 total time=  14.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=exponential, n_estimators=500;, score=-51110.321 total time=  32.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=exponential, n_estimators=500;, score=-51664.625 total time=  32.2s\n",
      "[CV 3/3] END learning_rate=0.1, loss=exponential, n_estimators=500;, score=-52929.792 total time=  32.5s\n",
      "[CV 1/3] END learning_rate=1.0, loss=linear, n_estimators=100;, score=-51664.403 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=linear, n_estimators=100;, score=-52323.886 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=1.0, loss=linear, n_estimators=100;, score=-53395.141 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=linear, n_estimators=200;, score=-51541.246 total time=  10.6s\n",
      "[CV 2/3] END learning_rate=1.0, loss=linear, n_estimators=200;, score=-52501.502 total time=  10.4s\n",
      "[CV 3/3] END learning_rate=1.0, loss=linear, n_estimators=200;, score=-53400.755 total time=  10.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=linear, n_estimators=500;, score=-52094.006 total time=  25.0s\n",
      "[CV 2/3] END learning_rate=1.0, loss=linear, n_estimators=500;, score=-52591.311 total time=  25.0s\n",
      "[CV 3/3] END learning_rate=1.0, loss=linear, n_estimators=500;, score=-53568.466 total time=  25.0s\n",
      "[CV 1/3] END learning_rate=1.0, loss=square, n_estimators=100;, score=-50760.838 total time=   5.2s\n",
      "[CV 2/3] END learning_rate=1.0, loss=square, n_estimators=100;, score=-51728.567 total time=   5.1s\n",
      "[CV 3/3] END learning_rate=1.0, loss=square, n_estimators=100;, score=-52455.513 total time=   5.2s\n",
      "[CV 1/3] END learning_rate=1.0, loss=square, n_estimators=200;, score=-50944.393 total time=   9.7s\n",
      "[CV 2/3] END learning_rate=1.0, loss=square, n_estimators=200;, score=-51066.089 total time=   9.5s\n",
      "[CV 3/3] END learning_rate=1.0, loss=square, n_estimators=200;, score=-52666.006 total time=   9.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=square, n_estimators=500;, score=-50464.728 total time=  22.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=square, n_estimators=500;, score=-51182.109 total time=  22.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=square, n_estimators=500;, score=-52444.482 total time=  22.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=-52049.276 total time=   5.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=-52808.059 total time=   5.8s\n",
      "[CV 3/3] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=-53363.430 total time=   5.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=-52155.760 total time=  10.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=-53054.144 total time=  10.8s\n",
      "[CV 3/3] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=-53387.709 total time=  10.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=exponential, n_estimators=500;, score=-52296.827 total time=  25.7s\n",
      "[CV 2/3] END learning_rate=1.0, loss=exponential, n_estimators=500;, score=-52858.244 total time=  25.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=exponential, n_estimators=500;, score=-54030.005 total time=  25.7s\n",
      "best parameters: {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 500}\n",
      "(15480, 16)\n",
      "AdaBoostRegressor: \n",
      "train, test RMSEs:  39063.92931534913 51582.91642891243\n",
      "train, test error rates: 0.189216875338952 0.24790945661836053\n"
     ]
    }
   ],
   "source": [
    "# Hypertune AdaBoostRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "adaRegressor = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8))\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=adaRegressor, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, verbose=3)\n",
    "grid_search.fit(Xtrain_prepared, ytrain_prepared)\n",
    "\n",
    "# Retrieve the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the testing data\n",
    "test_predictions = best_model.predict(Xtest_prepared)\n",
    "train_predictions = best_model.predict(Xtrain_prepared)\n",
    "\n",
    "# Evaluate the performance\n",
    "test_rmse = mean_squared_error(ytest_prepared, test_predictions, squared=False)\n",
    "train_rmse = mean_squared_error(ytrain_prepared, train_predictions, squared=False)\n",
    "\n",
    "\n",
    "adatest_predictions = best_model.predict(Xtest_prepared)\n",
    "adatrain_predictions = best_model.predict(Xtrain_prepared)\n",
    "\n",
    "adatest_rmse = mean_squared_error(ytest_prepared, adatest_predictions, squared=False)\n",
    "adatrain_rmse = mean_squared_error(ytrain_prepared, adatrain_predictions, squared=False)\n",
    "\n",
    "print(f\"best parameters: {best_params}\")\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"AdaBoostRegressor: \")\n",
    "print(\"train, test RMSEs: \", adatrain_rmse, adatest_rmse) # prints\n",
    "print(\"train, test error rates:\", adatrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 adatest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "ada_scores = {\"RMSE\": adatest_rmse, \"Error Rate\": adatest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "#hypertuning took way to long for barely any improvement, still worse than RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185a5212-055e-4aee-a4d6-61fbac978cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "GradientBoostingRegressor: \n",
      "train, test RMSEs:  28814.42073690006 46688.78977041334\n",
      "train, test error rates: 0.13957056425442194 0.22438809791034683\n"
     ]
    }
   ],
   "source": [
    "# Train with GradientBoostingRegressor\n",
    "\n",
    "gradientRegressor = GradientBoostingRegressor(max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8, \n",
    "                                    n_estimators = 500, learning_rate = 0.01,\n",
    "                                    subsample = 0.9)\n",
    "\n",
    "gradientRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "\n",
    "gradienttest_predictions = gradientRegressor.predict(Xtest_prepared)\n",
    "gradienttrain_predictions = gradientRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "gradienttest_rmse = mean_squared_error(ytest_prepared, gradienttest_predictions, squared=False)\n",
    "gradienttrain_rmse = mean_squared_error(ytrain_prepared, gradienttrain_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"GradientBoostingRegressor: \")\n",
    "print(\"train, test RMSEs: \", gradienttrain_rmse, gradienttest_rmse) # prints\n",
    "print(\"train, test error rates:\", gradienttrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 gradienttest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "gradient_scores = {\"RMSE\": gradienttest_rmse, \"Error Rate\": gradienttest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "#train, test error rates: [0.13957056] [0.224388] with subsample = 0.9 => error rate reduces 2%, \n",
    "#compared to AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4016d62-adb9-4ae9-92dc-106398ed035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-81949.120 total time=   3.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-82303.796 total time=   3.8s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-82593.556 total time=  47.8s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-82015.059 total time= 1.4min\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-82121.937 total time= 1.7min\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-82546.803 total time= 1.1min\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-81935.201 total time= 1.9min\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-82110.805 total time= 1.3min\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-82461.664 total time= 1.1min\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-81949.120 total time= 1.2min\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-82303.796 total time= 1.0min\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-82593.556 total time=  16.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-82015.059 total time=  10.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-82121.937 total time=   9.9s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-82546.803 total time=   9.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-81935.201 total time=   9.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-82110.805 total time=  10.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-82461.664 total time=   8.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-81949.120 total time=   5.4s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-82303.796 total time=   5.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-82593.556 total time=   5.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-82015.059 total time=   5.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-82121.937 total time=   4.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-82546.803 total time=   4.2s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-81935.201 total time=   4.7s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-82110.805 total time=   4.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-82461.664 total time=   4.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-81798.915 total time=   4.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-82155.564 total time=   4.2s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-82615.092 total time=   4.2s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-81780.002 total time=   4.7s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-82065.535 total time=   4.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-82553.006 total time=   4.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-81840.356 total time=   5.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-81971.047 total time=   5.2s\n",
      "[CV 3/3] END learning_rate=0.01, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-82437.411 total time=   5.2s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-88194.566 total time=   6.0s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-89640.997 total time=   6.0s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-88285.019 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-88145.061 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-89440.881 total time=   6.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-88094.390 total time=   6.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-87980.404 total time=   7.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-89390.260 total time=   7.2s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-87870.646 total time=   7.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-88194.566 total time=   6.0s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-89640.997 total time=   6.0s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-88285.019 total time=   6.0s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-88145.061 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-89440.881 total time=   6.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-88094.390 total time=   6.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-87980.404 total time=   7.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-89390.260 total time=   7.3s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-87870.646 total time=   7.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-88194.566 total time=   6.0s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-89640.997 total time=   6.0s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-88285.019 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-88145.061 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-89440.881 total time=   6.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-88094.390 total time=   6.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-87980.404 total time=   7.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-89390.260 total time=   7.2s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-87870.646 total time=   7.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-87950.995 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-89379.097 total time=   6.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-88277.068 total time=   6.6s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-87708.451 total time=   7.3s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-89164.356 total time=   7.3s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-87948.617 total time=   7.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-87597.485 total time=   7.9s\n",
      "[CV 2/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-88985.973 total time=   7.9s\n",
      "[CV 3/3] END learning_rate=0.01, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-87958.073 total time=   8.0s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-83559.453 total time=   8.3s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-84101.058 total time=   8.4s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-84456.498 total time=   8.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-83577.841 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-84059.533 total time=   9.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-84379.751 total time=   9.0s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-83578.322 total time=   9.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-84045.021 total time=   9.8s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-84430.469 total time=   9.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-83559.453 total time=   8.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-84101.058 total time=   8.4s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-84456.498 total time=   8.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-83577.841 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-84059.533 total time=   9.2s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-84379.751 total time=   9.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-83578.322 total time=   9.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-84045.021 total time=   9.8s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-84430.469 total time=   9.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-83559.453 total time=   8.3s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-84101.058 total time=   8.4s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-84456.498 total time=   8.4s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-83577.841 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-84059.533 total time=   9.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-84379.751 total time=   9.1s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-83578.322 total time=   9.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-84045.021 total time=   9.8s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-84430.469 total time=   9.9s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-83519.687 total time=   8.9s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-84139.854 total time=   9.0s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-84514.563 total time=   8.9s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-83516.394 total time=   9.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-83959.101 total time=   9.9s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-84379.970 total time=   9.8s\n",
      "[CV 1/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-83419.115 total time=  10.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-83960.499 total time=  10.6s\n",
      "[CV 3/3] END learning_rate=0.01, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-84380.389 total time=  10.6s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-161386.217 total time=   5.1s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-159973.372 total time=   5.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-161866.585 total time=   5.2s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-161286.790 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-159489.782 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-161335.722 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-160715.493 total time=   6.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-159080.405 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-161574.705 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-161386.217 total time=   5.1s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-159973.372 total time=   5.1s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-161866.585 total time=   5.2s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-161286.790 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-159489.782 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-161335.722 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-160715.493 total time=   6.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-159080.405 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-161574.705 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-161386.217 total time=   5.1s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-159973.372 total time=   5.2s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-161866.585 total time=   5.2s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-161286.790 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-159489.782 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-161335.722 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-160715.493 total time=   6.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-159080.405 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-161574.705 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-160786.934 total time=   5.6s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-159258.031 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-160348.218 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-160583.240 total time=   6.2s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-159414.374 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-160089.291 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-160923.956 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-158980.826 total time=   7.0s\n",
      "[CV 3/3] END learning_rate=0.01, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-159794.890 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-48477.898 total time=   3.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-47824.980 total time=   3.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-50153.260 total time=   3.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-48257.452 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-48139.018 total time=   4.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-49984.559 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-48120.394 total time=   4.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-48382.103 total time=   4.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-49523.074 total time=   4.7s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-48477.898 total time=   3.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-47824.980 total time=   3.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-50153.260 total time=   3.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-48257.452 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-48139.018 total time=   4.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-49984.559 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-48120.394 total time=   4.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-48382.103 total time=   4.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-49523.074 total time=   4.7s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-48477.898 total time=   3.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-47824.980 total time=   3.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-50153.260 total time=   3.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-48257.452 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-48139.018 total time=   4.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-49984.559 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-48120.394 total time=   4.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-48382.103 total time=   4.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-49523.074 total time=   4.7s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-47838.598 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-47802.532 total time=   4.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-49595.349 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-47789.938 total time=   4.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-47601.567 total time=   4.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-49808.925 total time=   4.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-47825.721 total time=   5.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-47842.318 total time=   5.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-49310.205 total time=   5.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-49493.386 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-48912.016 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-51146.812 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-49994.011 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-48803.447 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-50726.844 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-49643.807 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-48812.484 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-50907.672 total time=   6.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-49493.386 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-48912.016 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-51146.812 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-49994.011 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-48803.447 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-50726.844 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-49643.807 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-48812.484 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-50907.672 total time=   6.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-49493.386 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-48912.016 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-51146.812 total time=   5.7s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-49994.011 total time=   6.4s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-48803.447 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-50726.844 total time=   6.3s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-49643.807 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-48812.484 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-50907.672 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-49540.586 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-48856.262 total time=   6.3s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-50476.701 total time=   6.2s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-49134.949 total time=   6.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-48773.373 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-50570.196 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-49048.374 total time=   7.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-48367.606 total time=   7.6s\n",
      "[CV 3/3] END learning_rate=0.1, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-50582.603 total time=   7.4s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-48357.878 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-47355.955 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-49997.494 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-48095.421 total time=   7.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-47617.864 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-49926.310 total time=   7.5s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-48288.704 total time=   8.2s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-47619.822 total time=   8.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-49736.287 total time=   8.2s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-48357.878 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-47355.955 total time=   6.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-49997.494 total time=   6.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-48095.421 total time=   7.4s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-47617.864 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-49926.310 total time=   7.5s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-48288.704 total time=   8.2s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-47619.822 total time=   8.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-49736.287 total time=   8.2s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-48357.878 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-47355.955 total time=   6.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-49997.494 total time=   6.8s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-48095.421 total time=   7.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-47617.864 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-49926.310 total time=   7.5s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-48288.704 total time=   8.2s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-47619.822 total time=   8.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-49736.287 total time=   8.2s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-47945.614 total time=   7.4s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-47118.989 total time=   7.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-49264.142 total time=   7.4s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-47805.377 total time=   8.1s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-47275.525 total time=   8.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-49514.525 total time=   8.2s\n",
      "[CV 1/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-47782.640 total time=   8.9s\n",
      "[CV 2/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-47356.722 total time=   8.8s\n",
      "[CV 3/3] END learning_rate=0.1, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-49400.161 total time=   8.9s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-75031.683 total time=   5.0s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-75292.678 total time=   5.0s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-76634.611 total time=   5.0s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-76068.652 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-76276.800 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-77097.680 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-74762.167 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-75605.733 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-76866.461 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-75031.683 total time=   5.0s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-75292.678 total time=   5.0s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-76634.611 total time=   5.1s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-76068.652 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-76276.800 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-77097.680 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-74762.167 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-75605.733 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-76866.461 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-75031.683 total time=   5.0s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-75292.678 total time=   5.0s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-76634.611 total time=   5.0s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-76068.652 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-76276.800 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-77097.680 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-74762.167 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-75605.733 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-76866.461 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-74448.215 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-74849.077 total time=   5.6s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-76704.834 total time=   5.5s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-74699.658 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-74668.295 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-76580.545 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-74712.423 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-75106.906 total time=   6.7s\n",
      "[CV 3/3] END learning_rate=0.1, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-77139.775 total time=   6.7s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-63278.039 total time=   0.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-62838.326 total time=   0.5s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=0.8;, score=-64240.591 total time=   0.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-63818.110 total time=   0.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-60771.750 total time=   0.6s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=0.9;, score=-63580.464 total time=   0.5s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-61999.117 total time=   0.6s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-59858.866 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=5, subsample=1.0;, score=-61392.230 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-66277.922 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-64518.396 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=0.8;, score=-64648.724 total time=   0.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-66211.440 total time=   1.0s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-62830.837 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=0.9;, score=-64490.998 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-63089.831 total time=   1.1s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-62234.336 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=10, subsample=1.0;, score=-62457.193 total time=   1.2s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-75161.821 total time=   3.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-73331.570 total time=   3.8s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=0.8;, score=-72929.861 total time=   3.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-71159.253 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-69137.705 total time=   4.3s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=0.9;, score=-68361.897 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-67576.566 total time=   4.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-65800.383 total time=   4.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=50, subsample=1.0;, score=-65712.309 total time=   4.7s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-76473.996 total time=   4.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-70969.982 total time=   4.2s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=0.8;, score=-74464.965 total time=   4.2s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-67381.830 total time=   4.7s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-70445.208 total time=   4.8s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=0.9;, score=-70676.519 total time=   4.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-66923.837 total time=   5.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-67169.600 total time=   5.3s\n",
      "[CV 3/3] END learning_rate=1.0, loss=squared_error, n_iter_no_change=None, subsample=1.0;, score=-66092.862 total time=   5.3s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-62737.765 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-61712.163 total time=   0.8s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=0.8;, score=-61721.128 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-61045.083 total time=   1.0s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-62591.393 total time=   0.8s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=0.9;, score=-62703.182 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-60025.896 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-60434.511 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=5, subsample=1.0;, score=-60137.520 total time=   2.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-63826.067 total time=   1.4s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-61845.345 total time=   1.4s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=0.8;, score=-62430.896 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-61566.410 total time=   1.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-63122.103 total time=   1.6s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=0.9;, score=-62985.966 total time=   1.7s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-59902.693 total time=   1.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-60144.535 total time=   2.3s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=10, subsample=1.0;, score=-60210.477 total time=   2.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-65805.309 total time=   5.0s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-65131.901 total time=   4.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=0.8;, score=-64555.464 total time=   4.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-63167.172 total time=   5.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-63880.762 total time=   5.3s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=0.9;, score=-63999.818 total time=   5.3s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-60692.632 total time=   5.7s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-60559.397 total time=   5.6s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=50, subsample=1.0;, score=-60656.413 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-64310.612 total time=   5.4s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-64143.071 total time=   5.3s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=0.8;, score=-62443.285 total time=   5.2s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-60816.171 total time=   5.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-62417.717 total time=   5.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=0.9;, score=-62988.345 total time=   5.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-59599.563 total time=   6.2s\n",
      "[CV 2/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-59298.844 total time=   6.2s\n",
      "[CV 3/3] END learning_rate=1.0, loss=absolute_error, n_iter_no_change=None, subsample=1.0;, score=-60166.553 total time=   6.1s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-68976.763 total time=   5.6s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-68934.509 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=0.8;, score=-66331.150 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-65656.656 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-66250.144 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=0.9;, score=-67563.923 total time=   5.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-65276.359 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-63519.614 total time=   6.4s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=5, subsample=1.0;, score=-65412.823 total time=   6.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-68976.763 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-68934.509 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=0.8;, score=-70529.757 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-65656.656 total time=   6.0s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-66250.144 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=0.9;, score=-67563.923 total time=   5.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-65276.359 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-63519.614 total time=   6.4s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=10, subsample=1.0;, score=-65412.823 total time=   6.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-68976.763 total time=   5.6s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-68934.509 total time=   5.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=0.8;, score=-70529.757 total time=   5.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-65656.656 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-66250.144 total time=   6.1s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=0.9;, score=-67563.923 total time=   5.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-65276.359 total time=   6.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-63519.614 total time=   6.4s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=50, subsample=1.0;, score=-65412.823 total time=   6.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-70675.518 total time=   6.1s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-68340.286 total time=   6.0s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=0.8;, score=-71284.239 total time=   6.0s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-65099.766 total time=   6.6s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-64761.166 total time=   6.5s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=0.9;, score=-69498.393 total time=   6.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-64421.888 total time=   6.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-62421.696 total time=   6.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=huber, n_iter_no_change=None, subsample=1.0;, score=-63488.961 total time=   6.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-101772.847 total time=   1.0s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-102222.192 total time=   0.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=0.8;, score=-95814.400 total time=   0.7s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-97894.743 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-98343.575 total time=   0.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=0.9;, score=-95373.925 total time=   1.1s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-94043.380 total time=   0.9s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-96303.880 total time=   1.0s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=5, subsample=1.0;, score=-94310.507 total time=   0.9s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-100916.812 total time=   1.3s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-100482.772 total time=   1.2s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=0.8;, score=-93363.841 total time=   1.6s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-93547.450 total time=   2.2s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-97453.707 total time=   1.3s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=0.9;, score=-94964.304 total time=   1.4s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-92197.594 total time=   1.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-93988.569 total time=   1.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=10, subsample=1.0;, score=-91611.668 total time=   1.5s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-93253.201 total time=   4.9s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-95536.192 total time=   4.7s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=0.8;, score=-88882.749 total time=   4.8s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-89574.104 total time=   5.1s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-91459.656 total time=   5.0s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=0.9;, score=-89123.693 total time=   5.5s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-88017.084 total time=   5.4s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-89577.966 total time=   5.4s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=50, subsample=1.0;, score=-87068.748 total time=   5.5s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-90903.516 total time=   5.1s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-94083.630 total time=   5.1s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=0.8;, score=-94775.723 total time=   5.0s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-85463.186 total time=   5.5s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-89304.719 total time=   5.5s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=0.9;, score=-86464.356 total time=   5.5s\n",
      "[CV 1/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-86197.318 total time=   5.8s\n",
      "[CV 2/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-90782.827 total time=   5.9s\n",
      "[CV 3/3] END learning_rate=1.0, loss=quantile, n_iter_no_change=None, subsample=1.0;, score=-88826.013 total time=   6.1s\n",
      "best parameters: {'learning_rate': 0.1, 'loss': 'huber', 'n_iter_no_change': None, 'subsample': 0.8}\n",
      "(15480, 16)\n",
      "GradientBoostingRegressor: \n",
      "train, test RMSEs:  32637.1787909029 46969.15811804722\n",
      "train, test error rates: 0.15808714327841217 0.22573555884367136\n"
     ]
    }
   ],
   "source": [
    "# Hypertune Gradient\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "     'n_iter_no_change': [5, 10, 50, None]\n",
    "}\n",
    "\n",
    "gradientRegressor = GradientBoostingRegressor(max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8, \n",
    "                                    n_estimators = 50) #set it to 50 because 500 would take too long\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=gradientRegressor, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, verbose=3)\n",
    "grid_search.fit(Xtrain_prepared, ytrain_prepared)\n",
    "\n",
    "# Retrieve the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "gradienttest_predictions = best_model.predict(Xtest_prepared)\n",
    "gradienttrain_predictions = best_model.predict(Xtrain_prepared)\n",
    "\n",
    "gradienttest_rmse = mean_squared_error(ytest_prepared, gradienttest_predictions, squared=False)\n",
    "gradienttrain_rmse = mean_squared_error(ytrain_prepared, gradienttrain_predictions, squared=False)\n",
    "\n",
    "print(f\"best parameters: {best_params}\")\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"GradientBoostingRegressor: \")\n",
    "print(\"train, test RMSEs: \", gradienttrain_rmse, gradienttest_rmse) # prints\n",
    "print(\"train, test error rates:\", gradienttrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 gradienttest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "gradient_scores = {\"RMSE\": gradienttest_rmse, \"Error Rate\": gradienttest_rmse / np.mean(ytest_prepared)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86adf96a-b157-4b36-b0c5-e1136b60ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "GradientBoostingRegressor: \n",
      "train, test RMSEs:  17191.17060458117 46025.40763056079\n",
      "train, test error rates: 0.08327015848709227 0.22119985813627716\n"
     ]
    }
   ],
   "source": [
    "# Train with GradientBoostingRegressor now with 500 estimators using hypertuned parameters\n",
    "\n",
    "gradientRegressor = GradientBoostingRegressor(loss='huber', max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8, \n",
    "                                    n_estimators = 500, learning_rate = 0.1,\n",
    "                                    subsample = 0.8) \n",
    "\n",
    "gradientRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "\n",
    "gradienttest_predictions = gradientRegressor.predict(Xtest_prepared)\n",
    "gradienttrain_predictions = gradientRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "gradienttest_rmse = mean_squared_error(ytest_prepared, gradienttest_predictions, squared=False)\n",
    "gradienttrain_rmse = mean_squared_error(ytrain_prepared, gradienttrain_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"GradientBoostingRegressor: \")\n",
    "print(\"train, test RMSEs: \", gradienttrain_rmse, gradienttest_rmse) # prints\n",
    "print(\"train, test error rates:\", gradienttrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 gradienttest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "gradient_scores = {\"RMSE\": gradienttest_rmse, \"Error Rate\": gradienttest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "#train, test error rates: [0.0832701] [0.2211998] => error rate reduces 0.3%, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ee0fbe-a08a-4262-b49b-2d481dd4c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "HistogramGradienttBoostingRegressor: \n",
      "train, test RMSEs:  43948.83862661103 46025.40763056079\n",
      "train, test error rates: 0.21287827582761068 0.23641328883313348\n"
     ]
    }
   ],
   "source": [
    "# Histogram Gradient Boosting\n",
    "\n",
    "HGBRegressor = HistGradientBoostingRegressor(\n",
    "         max_depth=10, min_samples_leaf=10,\n",
    "         max_iter=500,\n",
    "         learning_rate=0.01, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "HGBRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "HGBtest_predictions = HGBRegressor.predict(Xtest_prepared)\n",
    "HGBtrain_predictions = HGBRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "HGBtest_rmse = mean_squared_error(ytest_prepared, HGBtest_predictions, squared=False)\n",
    "HGBtrain_rmse = mean_squared_error(ytrain_prepared, HGBtrain_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"HistogramGradienttBoostingRegressor: \")\n",
    "print(\"train, test RMSEs: \", HGBtrain_rmse, gradienttest_rmse) # prints\n",
    "print(\"train, test error rates:\", HGBtrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 HGBtest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "hist_scores = {\"RMSE\": HGBtest_rmse, \"Error Rate\": HGBtest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "#train, test error rates: [0.2128782] [0.2364132], about 1.5% worse than GradientBoosting\n",
    "# but HGB works much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a3c1a44-98d1-40eb-a5f3-5299403ce532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.01, loss=squared_error;, score=-48839.854 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.01, loss=squared_error;, score=-48708.967 total time=   2.6s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.01, loss=squared_error;, score=-50468.333 total time=   2.6s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.01, loss=absolute_error;, score=-51107.714 total time=   3.6s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.01, loss=absolute_error;, score=-50796.706 total time=   3.6s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.01, loss=absolute_error;, score=-52877.454 total time=   3.6s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.01, loss=gamma;, score=-48752.312 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.01, loss=gamma;, score=-49239.666 total time=   2.7s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.01, loss=gamma;, score=-50706.979 total time=   2.9s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.01, loss=poisson;, score=-48708.483 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.01, loss=poisson;, score=-48901.801 total time=   2.7s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.01, loss=poisson;, score=-50612.982 total time=   2.9s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.01, loss=quantile;, score=-51107.714 total time=   5.5s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.01, loss=quantile;, score=-50796.706 total time=   4.5s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.01, loss=quantile;, score=-52877.454 total time=   4.4s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.1, loss=squared_error;, score=-46670.340 total time=   0.9s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.1, loss=squared_error;, score=-45799.759 total time=   1.5s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.1, loss=squared_error;, score=-48149.367 total time=   0.7s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.1, loss=absolute_error;, score=-48054.249 total time=   2.0s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.1, loss=absolute_error;, score=-47211.732 total time=   1.4s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.1, loss=absolute_error;, score=-51262.088 total time=   0.7s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.1, loss=gamma;, score=-46604.304 total time=   0.7s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.1, loss=gamma;, score=-46308.985 total time=   1.1s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.1, loss=gamma;, score=-47758.093 total time=   0.9s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.1, loss=poisson;, score=-46776.954 total time=   0.8s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.1, loss=poisson;, score=-46353.665 total time=   1.0s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.1, loss=poisson;, score=-47761.559 total time=   0.9s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=0.1, loss=quantile;, score=-48054.249 total time=   2.4s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=0.1, loss=quantile;, score=-47211.732 total time=   1.8s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=0.1, loss=quantile;, score=-51262.088 total time=   0.8s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=1.0, loss=squared_error;, score=-57132.966 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=1.0, loss=squared_error;, score=-56890.727 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=1.0, loss=squared_error;, score=-57984.500 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=1.0, loss=absolute_error;, score=-54544.424 total time=   0.2s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=1.0, loss=absolute_error;, score=-55258.165 total time=   0.3s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=1.0, loss=absolute_error;, score=-55898.852 total time=   0.2s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=1.0, loss=gamma;, score=-56610.982 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=1.0, loss=gamma;, score=-56110.253 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=1.0, loss=gamma;, score=-59168.106 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=1.0, loss=poisson;, score=-63421.954 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=1.0, loss=poisson;, score=-66159.545 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=1.0, loss=poisson;, score=-62376.696 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.0, learning_rate=1.0, loss=quantile;, score=-54544.424 total time=   0.2s\n",
      "[CV 2/3] END l2_regularization=0.0, learning_rate=1.0, loss=quantile;, score=-55258.165 total time=   0.3s\n",
      "[CV 3/3] END l2_regularization=0.0, learning_rate=1.0, loss=quantile;, score=-55898.852 total time=   0.2s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.01, loss=squared_error;, score=-48774.776 total time=   2.6s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.01, loss=squared_error;, score=-48845.614 total time=   2.6s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.01, loss=squared_error;, score=-50509.078 total time=   2.6s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.01, loss=absolute_error;, score=-51167.765 total time=   3.6s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.01, loss=absolute_error;, score=-50397.659 total time=   3.6s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.01, loss=absolute_error;, score=-52589.323 total time=   3.6s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.01, loss=gamma;, score=-48757.790 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.01, loss=gamma;, score=-49053.837 total time=   2.7s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.01, loss=gamma;, score=-50665.544 total time=   2.7s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.01, loss=poisson;, score=-48708.492 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.01, loss=poisson;, score=-48739.474 total time=   2.7s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.01, loss=poisson;, score=-50612.982 total time=   2.7s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.01, loss=quantile;, score=-51167.765 total time=   4.4s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.01, loss=quantile;, score=-50397.659 total time=   4.6s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.01, loss=quantile;, score=-52589.323 total time=   4.4s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.1, loss=squared_error;, score=-46393.917 total time=   0.8s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.1, loss=squared_error;, score=-46392.377 total time=   0.8s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.1, loss=squared_error;, score=-47256.305 total time=   1.4s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.1, loss=absolute_error;, score=-48267.034 total time=   1.4s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.1, loss=absolute_error;, score=-46997.926 total time=   1.6s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.1, loss=absolute_error;, score=-49342.644 total time=   1.6s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.1, loss=gamma;, score=-46223.374 total time=   0.7s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.1, loss=gamma;, score=-46485.305 total time=   1.1s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.1, loss=gamma;, score=-47694.379 total time=   0.7s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.1, loss=poisson;, score=-46787.484 total time=   0.8s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.1, loss=poisson;, score=-46349.855 total time=   1.0s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.1, loss=poisson;, score=-47761.559 total time=   0.9s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=0.1, loss=quantile;, score=-48267.034 total time=   1.7s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=0.1, loss=quantile;, score=-46997.926 total time=   2.0s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=0.1, loss=quantile;, score=-49342.644 total time=   2.0s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=1.0, loss=squared_error;, score=-57612.321 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=1.0, loss=squared_error;, score=-57446.517 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=1.0, loss=squared_error;, score=-58167.673 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=1.0, loss=absolute_error;, score=-54805.425 total time=   0.2s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=1.0, loss=absolute_error;, score=-54456.714 total time=   0.2s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=1.0, loss=absolute_error;, score=-56369.071 total time=   0.2s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=1.0, loss=gamma;, score=-57586.017 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=1.0, loss=gamma;, score=-57848.600 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=1.0, loss=gamma;, score=-58789.060 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=1.0, loss=poisson;, score=-63421.953 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=1.0, loss=poisson;, score=-66141.944 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=1.0, loss=poisson;, score=-62376.696 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.1, learning_rate=1.0, loss=quantile;, score=-54805.425 total time=   0.2s\n",
      "[CV 2/3] END l2_regularization=0.1, learning_rate=1.0, loss=quantile;, score=-54456.714 total time=   0.2s\n",
      "[CV 3/3] END l2_regularization=0.1, learning_rate=1.0, loss=quantile;, score=-56369.071 total time=   0.2s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.01, loss=squared_error;, score=-48833.476 total time=   2.6s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.01, loss=squared_error;, score=-48864.758 total time=   2.6s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.01, loss=squared_error;, score=-50459.202 total time=   2.6s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.01, loss=absolute_error;, score=-51247.049 total time=   3.5s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.01, loss=absolute_error;, score=-50858.401 total time=   3.5s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.01, loss=absolute_error;, score=-52715.072 total time=   3.5s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.01, loss=gamma;, score=-48772.649 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.01, loss=gamma;, score=-49205.013 total time=   2.7s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.01, loss=gamma;, score=-50718.767 total time=   2.7s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.01, loss=poisson;, score=-48708.475 total time=   2.7s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.01, loss=poisson;, score=-48739.455 total time=   2.6s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.01, loss=poisson;, score=-50612.982 total time=   2.7s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.01, loss=quantile;, score=-51247.049 total time=   4.4s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.01, loss=quantile;, score=-50858.401 total time=   4.6s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.01, loss=quantile;, score=-52715.072 total time=   4.4s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.1, loss=squared_error;, score=-46484.155 total time=   0.7s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.1, loss=squared_error;, score=-45817.901 total time=   1.2s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.1, loss=squared_error;, score=-47543.878 total time=   0.9s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.1, loss=absolute_error;, score=-48511.338 total time=   1.3s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.1, loss=absolute_error;, score=-46901.191 total time=   2.0s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.1, loss=absolute_error;, score=-48935.491 total time=   1.7s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.1, loss=gamma;, score=-46624.660 total time=   0.6s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.1, loss=gamma;, score=-46901.914 total time=   0.8s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.1, loss=gamma;, score=-47769.872 total time=   0.9s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.1, loss=poisson;, score=-46789.077 total time=   0.8s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.1, loss=poisson;, score=-46349.855 total time=   1.0s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.1, loss=poisson;, score=-47768.204 total time=   0.9s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=0.1, loss=quantile;, score=-48511.338 total time=   1.6s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=0.1, loss=quantile;, score=-46901.191 total time=   2.5s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=0.1, loss=quantile;, score=-48935.491 total time=   2.1s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=1.0, loss=squared_error;, score=-59994.294 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=1.0, loss=squared_error;, score=-56850.523 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=1.0, loss=squared_error;, score=-58337.204 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=1.0, loss=absolute_error;, score=-55012.566 total time=   0.3s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=1.0, loss=absolute_error;, score=-54396.976 total time=   0.2s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=1.0, loss=absolute_error;, score=-55819.953 total time=   0.2s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=1.0, loss=gamma;, score=-59897.452 total time=   0.2s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=1.0, loss=gamma;, score=-57479.868 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=1.0, loss=gamma;, score=-59054.739 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=1.0, loss=poisson;, score=-63421.952 total time=   0.1s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=1.0, loss=poisson;, score=-66141.943 total time=   0.1s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=1.0, loss=poisson;, score=-62376.695 total time=   0.1s\n",
      "[CV 1/3] END l2_regularization=0.2, learning_rate=1.0, loss=quantile;, score=-55012.566 total time=   0.4s\n",
      "[CV 2/3] END l2_regularization=0.2, learning_rate=1.0, loss=quantile;, score=-54396.976 total time=   0.3s\n",
      "[CV 3/3] END l2_regularization=0.2, learning_rate=1.0, loss=quantile;, score=-55819.953 total time=   0.2s\n",
      "best parameters: {'l2_regularization': 0.2, 'learning_rate': 0.1, 'loss': 'squared_error'}\n",
      "(15480, 16)\n",
      "HistogramGradienttBoostingRegressor: \n",
      "train, test RMSEs:  33067.543332825226 46025.40763056079\n",
      "train, test error rates: 0.1601717321896261 0.2242036883210345\n"
     ]
    }
   ],
   "source": [
    "# hypertune Histogram Gradient Boosting\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'l2_regularization': [0.0, 0.1, 0.2],\n",
    "    'loss': ['squared_error', 'absolute_error', 'gamma', 'poisson', 'quantile'],\n",
    "}\n",
    "\n",
    "HGBRegressor = HistGradientBoostingRegressor(\n",
    "         max_depth=10, min_samples_leaf=10,\n",
    "         max_iter=500, quantile=0.5,\n",
    "         random_state=42)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=HGBRegressor, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, verbose=3)\n",
    "grid_search.fit(Xtrain_prepared, ytrain_prepared)\n",
    "\n",
    "# Retrieve the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "HGBtest_predictions = best_model.predict(Xtest_prepared)\n",
    "HGBtrain_predictions = best_model.predict(Xtrain_prepared)\n",
    "\n",
    "HGBtest_rmse = mean_squared_error(ytest_prepared, HGBtest_predictions, squared=False)\n",
    "HGBtrain_rmse = mean_squared_error(ytrain_prepared, HGBtrain_predictions, squared=False)\n",
    "\n",
    "print(f\"best parameters: {best_params}\")\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"HistogramGradienttBoostingRegressor: \")\n",
    "print(\"train, test RMSEs: \", HGBtrain_rmse, gradienttest_rmse) # prints\n",
    "print(\"train, test error rates:\", HGBtrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 HGBtest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "hist_scores = {\"RMSE\": HGBtest_rmse, \"Error Rate\": HGBtest_rmse / np.mean(ytest_prepared)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edf4c327-026c-419e-bda8-208596d511aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "HistogramGradienttBoostingRegressor: \n",
      "train, test RMSEs:  33067.543332825226 46025.40763056079\n",
      "train, test error rates: 0.1601717321896261 0.2242036883210345\n"
     ]
    }
   ],
   "source": [
    "# Histogram Gradient Boosting with tuned params\n",
    "\n",
    "HGBRegressor = HistGradientBoostingRegressor(\n",
    "         max_depth=10, min_samples_leaf=10,\n",
    "         max_iter=500, l2_regularization=0.2,\n",
    "         learning_rate=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "HGBRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "HGBtest_predictions = HGBRegressor.predict(Xtest_prepared)\n",
    "HGBtrain_predictions = HGBRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "HGBtest_rmse = mean_squared_error(ytest_prepared, HGBtest_predictions, squared=False)\n",
    "HGBtrain_rmse = mean_squared_error(ytrain_prepared, HGBtrain_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"HistogramGradienttBoostingRegressor: \")\n",
    "print(\"train, test RMSEs: \", HGBtrain_rmse, gradienttest_rmse) # prints\n",
    "print(\"train, test error rates:\", HGBtrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 HGBtest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "hist_scores = {\"RMSE\": HGBtest_rmse, \"Error Rate\": HGBtest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "# only .3% worse than gradient and a whole lot faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a40b6c4-aa0c-4aac-9e4b-05fa3f088fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 16)\n",
      "stackingRegressor: \n",
      "train, test RMSEs:  16969.283497424538 45999.69722882884\n",
      "train, test error rates: 0.08219538731506681 0.2210762929685032\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "\n",
    "stackRegressor = StackingRegressor(estimators = [\n",
    "    ('GradientBoostingRegressor', GradientBoostingRegressor(loss='huber', max_depth = 10, \n",
    "                                    min_samples_leaf=10,\n",
    "                                    random_state=42, max_features = 0.8, \n",
    "                                    n_estimators = 500, learning_rate = 0.1,\n",
    "                                    subsample = 0.8)),\n",
    "        \n",
    "    ('RF', RandomForestRegressor(max_depth = 20, \n",
    "                                    min_samples_leaf=4, min_samples_split=2,\n",
    "                                    random_state=42, max_features = 0.8,\n",
    "                                    n_estimators = 1000, max_samples = 0.5,\n",
    "                                    n_jobs=-1))\n",
    "    ],\n",
    "                                   \n",
    "    final_estimator = LinearRegression(),\n",
    "    cv = 5, n_jobs = -1\n",
    ")\n",
    "\n",
    "stackRegressor.fit(Xtrain_prepared,np.ravel(ytrain_prepared))\n",
    "\n",
    "\n",
    "stacktest_predictions = stackRegressor.predict(Xtest_prepared)\n",
    "stacktrain_predictions = stackRegressor.predict(Xtrain_prepared)\n",
    "\n",
    "stacktest_rmse = mean_squared_error(ytest_prepared, stacktest_predictions, squared=False)\n",
    "stacktrain_rmse = mean_squared_error(ytrain_prepared, stacktrain_predictions, squared=False)\n",
    "\n",
    "print(Xtrain_prepared.shape)\n",
    "print(\"stackingRegressor: \")\n",
    "print(\"train, test RMSEs: \", stacktrain_rmse, stacktest_rmse) # prints\n",
    "print(\"train, test error rates:\", stacktrain_rmse / np.mean(ytrain_prepared),#.values,\n",
    "                                 stacktest_rmse / np.mean(ytest_prepared))#.values)\n",
    "\n",
    "stack_scores = {\"RMSE\": stacktest_rmse, \"Error Rate\": stacktest_rmse / np.mean(ytest_prepared)}\n",
    "\n",
    "#train, test error rates: [0.08219538] [0.22107629] \n",
    "#the ensemble's performance is ever so slightly better than the GradientBoostingRegressor is on the test\n",
    "#but the train error rate goes down (by 2%). That is good as it makes zoom for regularization to\n",
    "#reducing the error rate on test\n",
    "\n",
    "#your turn:\n",
    "#1 try to include the best versions of ensembles you have got in the stacking ensemble to \n",
    "#get better final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ca22d60-3f80-4455-ad33-bc14ee5fb4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Error Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VotingRegressor</th>\n",
       "      <td>73709.641585</td>\n",
       "      <td>0.354251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>65270.918856</td>\n",
       "      <td>0.313695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>51582.916429</td>\n",
       "      <td>0.247909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>50645.084055</td>\n",
       "      <td>0.243402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>46650.419373</td>\n",
       "      <td>0.224204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>46025.407631</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StackingRegressor</th>\n",
       "      <td>45999.697229</td>\n",
       "      <td>0.221076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       RMSE  Error Rate\n",
       "VotingRegressor                73709.641585    0.354251\n",
       "BaggingRegressor               65270.918856    0.313695\n",
       "AdaBoostRegressor              51582.916429    0.247909\n",
       "RandomForest                   50645.084055    0.243402\n",
       "HistGradientBoostingRegressor  46650.419373    0.224204\n",
       "GradientBoostingRegressor      46025.407631    0.221200\n",
       "StackingRegressor              45999.697229    0.221076"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(data=(voting_scores, bagging_scores, forest_scores, ada_scores, gradient_scores, hist_scores, stack_scores),\n",
    "                     index=[\"VotingRegressor\", \"BaggingRegressor\", \"RandomForest\", \"AdaBoostRegressor\", \n",
    "                            \"GradientBoostingRegressor\", \"HistGradientBoostingRegressor\", \"StackingRegressor\"]\n",
    "                     ).sort_values(\"Error Rate\", ascending=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4732dc9-f2ce-4e87-b793-d01a33972dfe",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The best overall algorithm ended up being Stacking Regressor with and error rate of 22.1076%, which is pretty solid. It was only a little bit better than Gradient and histogram boosting, but this makes sense as the stacking regressor combines the strong algorithms to make a slight stronger algorithm. For my stacking Regressor I used Random forest and GradientBoostin to get the final model. I choose not to use hist because it is nearly the same as Gradient, only slightly worse, so it would feel redundant. It is not surprising that Voting performed the worst, because it uses a lot of weak algorithms, includong ones that had high error rates, like SVR and SGDRegressor. I ended up using DecisionTree for most bass algorithms because it performed the best out of the regressors in the Voting, so it makes sense why Gradient did so well, as it optimizes for DecisionTree. Overall this leads to aStacking being the best, because it uses the strong algorithms in GradientBoosting and RandomForest, and combines them into a slightly better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b29981-9df3-4416-aa9e-20149060a807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
